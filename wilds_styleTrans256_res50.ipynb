{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835c2f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lcy/anaconda3/envs/strap/bin/jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83391815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 25 11:13:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8    12W / 270W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8    10W / 270W |     71MiB / 11175MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A      1255      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    1   N/A  N/A      1485      G   /usr/bin/gnome-shell               28MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a6a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import random\n",
    "from random import shuffle\n",
    "import copy\n",
    "import pickle\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85397ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3066316",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=8\n",
    "imgSize=int(96)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d872e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = transforms.Compose([transforms.ToPILImage(),\n",
    "                              #stain_norm(),\n",
    "                              #transforms.ToPILImage(),\n",
    "                              # transforms.Resize(imgSize),\n",
    "                              transforms.RandomResizedCrop(imgSize),\n",
    "                              transforms.RandomHorizontalFlip(p=0.5),\n",
    "                              transforms.RandomVerticalFlip(p=0.5),\n",
    "                              # transforms.RandomResizedCrop(imgSize, scale=(0.8, 1.0), ratio=(1, 1)),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.Resize(imgSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be3252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root_path = '../data/patches'\n",
    "h5_path = '/media/dnr/data_crypt/cy_strap/output_96/style_High_Renaissance_96_1024_256_alpha10.hdf5'\n",
    "csv_path = '/media/dnr/data_crypt/cy_strap/metadata_fnames_splits_modSplit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = glob.glob(f'{data_root_path}/*/*.png')\n",
    "# len(image_paths), image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2b05c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455954, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path); df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84fb8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient</th>\n",
       "      <th>node</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>tumor</th>\n",
       "      <th>slide</th>\n",
       "      <th>center</th>\n",
       "      <th>split</th>\n",
       "      <th>fnames</th>\n",
       "      <th>data_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/patches/patient_004_node_4/patch_patie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3200</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/patches/patient_004_node_4/patch_patie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3168</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/patches/patient_004_node_4/patch_patie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/patches/patient_004_node_4/patch_patie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3232</td>\n",
       "      <td>22240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/patches/patient_004_node_4/patch_patie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  patient  node  x_coord  y_coord  tumor  slide  center  split  \\\n",
       "0           0        4     4     3328    21792      1      0       0      0   \n",
       "1           1        4     4     3200    22272      1      0       0      0   \n",
       "2           2        4     4     3168    22272      1      0       0      0   \n",
       "3           3        4     4     3328    21760      1      0       0      0   \n",
       "4           4        4     4     3232    22240      1      0       0      0   \n",
       "\n",
       "                                              fnames data_split  \n",
       "0  ../data/patches/patient_004_node_4/patch_patie...      train  \n",
       "1  ../data/patches/patient_004_node_4/patch_patie...      train  \n",
       "2  ../data/patches/patient_004_node_4/patch_patie...      train  \n",
       "3  ../data/patches/patient_004_node_4/patch_patie...      train  \n",
       "4  ../data/patches/patient_004_node_4/patch_patie...      train  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6c8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(h5_path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864c17e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['img']>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae8425b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'filenames' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0b51aca1303c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filenames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# fnames[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# f\"../{'/'.join(fnames[0].split('/')[-4:])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fnames = [f\"../{'/'.join(i.decode('UTF-8').split('/')[-4:])}\" for i in h5['filenames']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fnames[10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/lcy/anaconda3/envs/strap/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'filenames' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "fnames = [i.decode('UTF-8') for i in h5['filenames']]\n",
    "# fnames[0]\n",
    "# f\"../{'/'.join(fnames[0].split('/')[-4:])}\"\n",
    "# fnames = [f\"../{'/'.join(i.decode('UTF-8').split('/')[-4:])}\" for i in h5['filenames']]\n",
    "# fnames[10]\n",
    "# fnames.index(df.fnames[10])\n",
    "# fnames[145004] == df.fnames[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b566306d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Unable to open object (bad object header version number)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-16ba2472c533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/lcy/anaconda3/envs/strap/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unable to open object (bad object header version number)'"
     ]
    }
   ],
   "source": [
    "h5['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32350474",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Unable to open object (bad object header version number)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8bdc65fb673b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m145004\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/lcy/anaconda3/envs/strap/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unable to open object (bad object header version number)'"
     ]
    }
   ],
   "source": [
    "h5['img'][145004].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(h5['img'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, h5_path=h5_path, csv_path=csv_path, dset_type='train', transform=None):\n",
    "        \"\"\"\n",
    "        dset_type: [\"train\", \"val\", \"test\"]\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.df = df[df.data_split==dset_type]\n",
    "        self.fnames = self.df.fnames.tolist()\n",
    "        self.labels = self.df.tumor.tolist()\n",
    "        \n",
    "        h5 = h5py.File(h5_path, mode='r')\n",
    "        self.imgs = h5['img']\n",
    "        self.h5_fnames = [f\"../{'/'.join(i.decode('UTF-8').split('/')[-4:])}\" for i in h5['filenames']]\n",
    "        \n",
    "        self.transform=transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self.fnames[index]\n",
    "        label = self.labels[index]\n",
    "        h5_index = self.h5_fnames.index(fname)\n",
    "        img = self.imgs[h5_index]\n",
    "        \n",
    "        assert img.shape[2] == 3, 'image channel num is not 3'\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "loaders = {}\n",
    "\n",
    "for dset_type in ['train', 'val', 'test']:\n",
    "    if dset_type == 'train':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = augment)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=True)\n",
    "    elif dset_type == 'val':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = transform)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=True)\n",
    "    elif dset_type == 'test':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = transform)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=False)\n",
    "    print('Finished loading %s dataset: %s samples' % (dset_type, len(datasets[dset_type])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f146eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "\n",
    "#     model = models.mobilenet_v2(pretrained=True)\n",
    "#     model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, num_classes))\n",
    "    \n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(num_ftrs, num_classes))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loaders, criterion, optimizer, scheduler, num_epochs=40, estop=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = float(\"inf\")\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            for inputs, labels in loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            ##########\n",
    "            \n",
    "#             while True:\n",
    "#                 try:\n",
    "#                     inputs, labels = next(loaders[phase])\n",
    "\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     optimizer.zero_grad()\n",
    "\n",
    "#                     with torch.set_grad_enabled(phase == 'train'):\n",
    "#                         outputs = model(inputs)\n",
    "#                         _, preds = torch.max(outputs, 1)\n",
    "#                         loss = criterion(outputs, labels)\n",
    "\n",
    "#                         if phase == 'train':\n",
    "#                             loss.backward()\n",
    "#                             optimizer.step()\n",
    "\n",
    "#                     running_loss += loss.item() * inputs.size(0)\n",
    "#                     running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val':\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                if epoch_loss < best_loss:\n",
    "                    best_epoch = epoch\n",
    "                    best_loss = epoch_loss\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "\n",
    "        print()\n",
    "\n",
    "        if counter >= estop:\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, best_loss, best_acc, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aed702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_classes)\n",
    "model = model.to('cuda')\n",
    "\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.004, momentum=0.9, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model, best_loss, best_acc, best_epoch = \\\n",
    "    train_model(model, loaders, criterion, optimizer, scheduler=None, num_epochs=60, estop=5)\n",
    "torch.save(model.state_dict(), 'state_dicts/wilds_style_transfer96_res50_modSplit6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = '../data/patches'\n",
    "csv_path = '../data/metadata_fnames_splits_modSplit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, data_root_path=data_root_path, csv_path=csv_path, dset_type='train', transform=None):\n",
    "        \"\"\"\n",
    "        dset_type: [\"train\", \"val\", \"test\"]\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        self.df = df[df.data_split==dset_type]\n",
    "        self.fnames = self.df.fnames.tolist()\n",
    "        self.labels = self.df.tumor.tolist()\n",
    "        self.transform=transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self.fnames[index]\n",
    "        label = self.labels[index]\n",
    "        img = np.array(Image.open(fname), dtype='uint8')\n",
    "        \n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:,:,:3]\n",
    "        elif img.shape[2] != 3:\n",
    "            raise ValueError('image channel num is not 3')\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6155b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "loaders = {}\n",
    "\n",
    "for dset_type in ['train', 'val', 'test']:\n",
    "    if dset_type == 'train':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = augment)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    elif dset_type == 'val':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = transform)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    elif dset_type == 'test':\n",
    "        datasets[dset_type] = MyDataset(dset_type=dset_type, transform = transform)\n",
    "        loaders[dset_type] = torch.utils.data.DataLoader(datasets[dset_type], batch_size=batchSize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    print('Finished loading %s dataset: %s samples' % (dset_type, len(datasets[dset_type])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ca6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea760d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, dataset_size, criterion):\n",
    "    \n",
    "    print('-' * 10)\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    whole_probs = torch.FloatTensor(dataset_size)\n",
    "    whole_labels = torch.LongTensor(dataset_size)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i, data in enumerate(loader):\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            whole_probs[i*batchSize:i*batchSize+inputs.size(0)]=outputs.detach()[:,1].clone()\n",
    "            whole_labels[i*batchSize:i*batchSize+inputs.size(0)]=labels.detach().clone()\n",
    "\n",
    "        total_loss = running_loss / dataset_size\n",
    "        total_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f}'.format(total_loss, total_acc))\n",
    "\n",
    "    return whole_probs.cpu().numpy(), whole_labels.cpu().numpy(), total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def bootstrap_auc(y_true, y_pred, n_bootstraps=1000, rng_seed=42):\n",
    "    n_bootstraps = n_bootstraps\n",
    "    rng_seed = rng_seed  # control reproducibility\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    for i in range(n_bootstraps):\n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        indices = rng.randint(len(y_pred), size=len(y_pred))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "        score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "#         print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "    bootstrapped_scores = np.array(bootstrapped_scores)\n",
    "\n",
    "    print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "        np.percentile(bootstrapped_scores, (2.5, 97.5))[0], np.percentile(bootstrapped_scores, (2.5, 97.5))[1]))\n",
    "    \n",
    "    return np.percentile(bootstrapped_scores, (2.5, 97.5))[0], np.percentile(bootstrapped_scores, (2.5, 97.5))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 1.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test, label_test, loss_test, acc_test = test_model(model, loaders['test'], dataset_sizes['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e81537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = [1 if prob>0.50 else 0 for prob in prob_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(label_test, pred_test)\n",
    "print(cm)\n",
    "acc = (cm[0][0]+cm[1][1])/len(pred_test)*100\n",
    "print('accuracy = ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6555d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'tile-wise AUC is {roc_auc_score(label_test, prob_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec71bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(label_test, prob_test)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "ci_low, ci_high = bootstrap_auc(np.array(label_test), np.array(prob_test))\n",
    "print(f'AUROC = {roc_auc} with 95CI of {ci_low}-{ci_high}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes=[\"normal\", \"tumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate, color=\"teal\", label=\"AUC = %0.2f\" % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0,1],[0,1], color=\"lightcoral\", ls=\"--\")\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
